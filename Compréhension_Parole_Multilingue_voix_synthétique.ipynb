{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtFs785E6lQr",
        "outputId": "f9676762-0cea-4625-aa58-091ace55473b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# importation des données depuis drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u_crB7zmY21",
        "outputId": "92315c3a-9da0-40e4-a30a-7d7fba25f31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Comp_DataSets_slu.zip\n",
            "replace /content/drive/MyDrive/Dataset/Comp_DataSets_slu/Test/Certificat/AR_A_F_C_1.wav? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "#décomprésser les données importées depuis le drive\n",
        "!unzip /content/drive/MyDrive/Comp_DataSets_slu.zip -d  /content/drive/MyDrive/Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgL-Nn-N5nQN"
      },
      "outputs": [],
      "source": [
        "#importation des bibiothèques\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiS1tLJC5szX"
      },
      "outputs": [],
      "source": [
        "#funtion load and extract\n",
        "def load_data(data_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for folder in os.listdir(data_path):\n",
        "        folder_path = os.path.join(data_path, folder)\n",
        "\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "            # Load audio data\n",
        "            audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
        "\n",
        "            # Extract MFCC features\n",
        "            mfccs = librosa.feature.mfcc(y=audio_data, sr=sampling_rate, n_mfcc=17)\n",
        "\n",
        "            # Calculate mean and standard deviation of MFCCs\n",
        "            mfccs_mean = np.mean(mfccs, axis=1)\n",
        "            mfccs_std = np.std(mfccs, axis=1)\n",
        "\n",
        "            # Flatten arrays before concatenation\n",
        "            mfccs_mean_flat = mfccs_mean.flatten()\n",
        "            mfccs_std_flat = mfccs_std.flatten()\n",
        "\n",
        "\n",
        "            # Extract Pitch feature\n",
        "            pitches, magnitudes = librosa.core.piptrack(y=audio_data, sr=sampling_rate)\n",
        "            pitch_mean = np.mean(pitches)\n",
        "            pitch_std = np.std(pitches)\n",
        "\n",
        "            # Combine features into a single feature vector\n",
        "            features = np.concatenate((mfccs_mean_flat, mfccs_std_flat,[pitch_mean,pitch_std]), axis=0)\n",
        "\n",
        "            # Extract information from the file name\n",
        "            pattern = r'(\\w+)_(\\w)_(\\w)_(\\w)_(\\d+)\\.wav'\n",
        "            match = re.match(pattern, file_name)\n",
        "            if match:\n",
        "                language, agent_id, agent_sex, classe, index = match.groups()\n",
        "\n",
        "                # Determine labels\n",
        "                label_language = language\n",
        "                label_agent_sex = agent_sex\n",
        "                label_agent_id = agent_id\n",
        "                label_agent_class = classe\n",
        "\n",
        "                # Add data and labels to the lists\n",
        "                data.append({'features': features, 'sampling_rate': sampling_rate})\n",
        "                labels.append({'language': label_language, 'agent_id': label_agent_id, 'class': label_agent_class})\n",
        "\n",
        "    return data, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFsmIQzFLYbf"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "data_path_train = '/content/drive/MyDrive/Dataset/Comp_DataSets_slu/Train'\n",
        "data_path_test = '/content/drive/MyDrive/Dataset/Comp_DataSets_slu/Test'\n",
        "X_train, y_train = load_data(data_path_train)\n",
        "X_test, y_test = load_data(data_path_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN71es7pLmQY"
      },
      "outputs": [],
      "source": [
        "# Extract features and convert to numpy arrays\n",
        "X_train_features = np.array([sample['features'] for sample in X_train])\n",
        "X_test_features = np.array([sample['features'] for sample in X_test])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepossessing data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_features)\n",
        "X_test_scaled = scaler.transform(X_test_features)\n"
      ],
      "metadata": {
        "id": "uWHBRv_Q0Llf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL7wb5Vq0QAJ",
        "outputId": "ac58ada8-2a83-40c9-b5c8-51081d63a4e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1134, 36)\n",
            "(644, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_e9qasg5wOo"
      },
      "outputs": [],
      "source": [
        "# extract each label\n",
        "y_train_language = ([sample['language'] for sample in y_train])\n",
        "y_train_agent_id = ([sample['agent_id'] for sample in y_train])\n",
        "y_train_class = ([sample['class'] for sample in y_train])\n",
        "# Assuming y_test is your list of dictionaries for testing data\n",
        "y_test_language = ([sample['language'] for sample in y_test])\n",
        "y_test_agent_id = ([sample['agent_id'] for sample in y_test])\n",
        "y_test_class = ([sample['class'] for sample in y_test])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the training and test sets for cross-validation\n",
        "X_combined = np.concatenate((X_train_scaled, X_test_scaled), axis=0)\n",
        "y_combined = np.concatenate((y_train_class, y_test_class), axis=0)"
      ],
      "metadata": {
        "id": "t5RjZU5B0rbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create MLPClassifier\n",
        "mlp_classifier = MLPClassifier(\n",
        "    activation='relu',\n",
        "    random_state=11,\n",
        "    learning_rate='adaptive',\n",
        "    solver='adam',\n",
        "    max_iter=1000,\n",
        "    hidden_layer_sizes=(5000, 500, 50),\n",
        "    learning_rate_init=0.001,\n",
        "    alpha=0.01,\n",
        ")"
      ],
      "metadata": {
        "id": "lpEaOWx41EeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RandomForestClassifier without class weights\n",
        "rf_classifier = RandomForestClassifier(\n",
        "    random_state=19,\n",
        "    n_estimators=1000\n",
        ")\n"
      ],
      "metadata": {
        "id": "SksaCSvP1HGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('mlp', mlp_classifier), ('rf', rf_classifier)],\n",
        "    voting='hard'\n",
        ")"
      ],
      "metadata": {
        "id": "qyxdFwoE1JmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create StratifiedKFold for cross-validation\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "ZcOJ_zhW-i7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u05sBZKTeHCz"
      },
      "outputs": [],
      "source": [
        "# Cross-validate the ensemble model\n",
        "cv_scores = cross_val_score(voting_classifier, X_combined, y_combined, cv=stratified_kfold, scoring='accuracy')\n",
        "# Cross-validate the ensemble model and get predicted labels\n",
        "predicted_labels = cross_val_predict(voting_classifier, X_combined, y_combined, cv=stratified_kfold)\n",
        "# Obtain the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_combined, predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
        "# Classification Report\n",
        "classification_report_result = classification_report(y_combined, predicted_labels)\n",
        "# Print the confusion matrix\n",
        "print(\"\\nConfusion Matrix (based on mean cross-validation scores):\")\n",
        "print(conf_matrix)\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report (based on mean cross-validation scores):\")\n",
        "print(classification_report_result)"
      ],
      "metadata": {
        "id": "FU4B0HUU1VmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c22d4fb-09dc-4d53-b61d-e506b23559b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.85955056 0.79775281 0.85674157 0.85352113 0.83943662]\n",
            "Mean Accuracy: 0.8414005380598196\n",
            "\n",
            "Confusion Matrix (based on mean cross-validation scores):\n",
            "[[336   8  62]\n",
            " [ 20 233  69]\n",
            " [ 65  58 927]]\n",
            "\n",
            "Classification Report (based on mean cross-validation scores):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.80      0.83      0.81       406\n",
            "           D       0.78      0.72      0.75       322\n",
            "           N       0.88      0.88      0.88      1050\n",
            "\n",
            "    accuracy                           0.84      1778\n",
            "   macro avg       0.82      0.81      0.81      1778\n",
            "weighted avg       0.84      0.84      0.84      1778\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}